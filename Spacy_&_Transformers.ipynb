{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61cca9a4-f86f-4056-a58a-7579cbceaacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name and Entity and recognition\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71bd401d-95dd-4e53-bbcf-149cf470e1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elon Musk-PERSON\n",
      "2002-DATE\n",
      "Tesla-ORG\n",
      "2003-DATE\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Elon Musk founded SpaceX in 2002 and Tesla in 2003.\")\n",
    "for ent in doc.ents: print(f\"{ent.text}-{ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "798dcb9f-c46f-4684-95c2-ae99c11477d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elon-PROPN\n",
      "Musk-PROPN\n",
      "founded-VERB\n",
      "SpaceX-PROPN\n",
      "in-ADP\n",
      "2002-NUM\n",
      "and-CCONJ\n",
      "Tesla-PROPN\n",
      "in-ADP\n",
      "2003-NUM\n",
      ".-PUNCT\n"
     ]
    }
   ],
   "source": [
    "#Part Of speech Tagging \n",
    "for token in doc:\n",
    "    print(f\"{token.text}-{token.pos_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d400b9c-bccd-4c2a-9a3c-2714d4668c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9994693398475647}]\n"
     ]
    }
   ],
   "source": [
    "#Sentiment Analysis\n",
    "from transformers import pipeline\n",
    "sentiment_model = pipeline(\"sentiment-analysis\")\n",
    "result =  sentiment_model(\"I love Natural Language Processing!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09fa6b0b-a3db-4fba-90e8-fb69ba018c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' Natural Language Processing (NLP) is a subfield of artificial intelligence that focuses on the interaction between computers and humans using natural language .'}]\n"
     ]
    }
   ],
   "source": [
    "#Text Summarization\n",
    "summarizer = pipeline(\"summarization\")\n",
    "text = \"\"\"\n",
    "Natural Language Processing (NLP) is a subfield of artificial intelligence that focuses on the interaction between computers and humans using natural language. It enables machines to read, understand, and derive meaning from text and speech. \"\"\"\n",
    "summary = summarizer(text, max_length=30, min_length=10 , do_sample=False)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09e48296-92d6-473d-8cac-b57fdbdb0f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"Once upon a time, there was an AI that could do things like this, but now it's going to turn into a machine, a machine with a whole bunch of AI that can do things like that. Even though you've got all these different AI parts that all interact, you're going to have these different AI parts that you can interact with, but they're all going to be very different and very different.\\n\\n\\nI think there's so much more to this game than just AI. I think there's a lot more that goes into this game than just AI. I think there's so much more that goes into this game than just AI. I think there's a lot more that goes into this game than just AI.\\n\\n\\nTODAY: What's the most intimidating part about this game? It's so much more, you know? It's so much more, you know? It's so much more.\\n\\n\\nI think it's very exciting. I think it's a little bit like the first half of The Sims 3, where you had a bunch of other Sims who were doing it and you were a bunch of other Sims who were doing it, and then the game was like, well, you know what? You're still going to do it, you still have this little machine\"}]\n"
     ]
    }
   ],
   "source": [
    "#Text Generation\n",
    "from transformers import pipeline\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "generated_text = generator(\"Once upon a time, there was an AI\", max_length=50, num_return_sequences=1)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7960f06-ebd1-4284-81f0-f746677a33be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
